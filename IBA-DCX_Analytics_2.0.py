import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import matplotlib as mpl
import os
import time
import re
import base64
import tempfile
import random
import itertools
import gc
import networkx as nx
import squarify
import urllib.request
import datetime
import pytz
import uuid
from collections import Counter, defaultdict
from wordcloud import WordCloud
from transformers import pipeline
from gensim import corpora
from gensim.models import LdaModel
import pyLDAvis.gensim as gensimvis
import pyLDAvis
import altair as alt
import gspread
from random import choice
from google.oauth2.service_account import Credentials

#---GOOGLETRANS API TRY----
try:
    from googletrans import Translator
except ImportError:
    Translator = None

def translate_texts(texts, target_lang):
    if Translator is None:
        return texts  # Fallback: show originals if package missing
    translator = Translator()
    translated = []
    for text in texts:
        try:
            t = translator.translate(text, dest=target_lang).text
            translated.append(t)
        except Exception:
            translated.append(text)
    return translated


# --- Bilingual UI Setup ---
lang = st.sidebar.selectbox("ğŸŒ Language / Idioma", ["English", "EspaÃ±ol"], key="lang")

TRANSLATIONS = {
    "The maximum number of users has been reached. Estimated waiting time: {m}ë¶„":
        {"English": "The maximum number of users has been reached. Estimated waiting time: {m} min",
         "EspaÃ±ol": "Se alcanzÃ³ el nÃºmero mÃ¡ximo de usuarios. Tiempo estimado de espera: {m} min"},
    "â° Your session time has ended. Please reconnect.":
        {"English": "â° Your session time has ended. Please reconnect.",
         "EspaÃ±ol": "â° Tu sesiÃ³n ha terminado. Por favor vuelve a conectarte."},
    "â³ Your expiration time: {expiration_str}":
        {"English": "â³ Your expiration time: {expiration_str}",
         "EspaÃ±ol": "â³ Tu sesiÃ³n expira: {expiration_str}"},
    "âœ… Finish the session":
        {"English": "âœ… Finish the session", "EspaÃ±ol": "âœ… Finalizar sesiÃ³n"},
    "âœ… The session has ended.":
        {"English": "âœ… The session has ended.", "EspaÃ±ol": "âœ… La sesiÃ³n ha terminado."},
    "ğŸ“Š IBA-DCX Tool":
        {"English": "ğŸ“Š IBA-DCX Tool", "EspaÃ±ol": "ğŸ“Š Herramienta IBA-DCX"},
    "How to Use": {"English": "How to Use", "EspaÃ±ol": "CÃ³mo usar"},
     "Review Summary and Images":
        {"English": "Review Summary and Images", "EspaÃ±ol": "Resumen de ReseÃ±as y Fotos"},
    "Review Indicators":
        {"English": "Review Indicators", "EspaÃ±ol": "Indicadores de ReseÃ±as"},
    "Total number of Reviews":
        {"English": "Total number of Reviews", "EspaÃ±ol": "Total de ReseÃ±as"},
    "Total number of Images":
        {"English": "Total number of Images", "EspaÃ±ol": "Total de Fotos"},
    "Images":
        {"English": "Images", "EspaÃ±ol": "Fotos"},
    "Reviews":
        {"English": "Reviews", "EspaÃ±ol": "ReseÃ±as"},
    "Average Review Length":
        {"English": "Average Review Length", "EspaÃ±ol": "Longitud Promedio de ReseÃ±a"},
    "Top Reviews ğŸ–¼ï¸":
        {"English": "Top Reviews ğŸ–¼ï¸", "EspaÃ±ol": "ReseÃ±as Destacadas ğŸ–¼ï¸"},
    "ğŸ”„ Look at other reviews":
        {"English": "ğŸ”„ Look at other reviews", "EspaÃ±ol": "ğŸ”„ Ver otras reseÃ±as"},
    "Wordcloud":
        {"English": "Wordcloud", "EspaÃ±ol": "Nube de Palabras"},
    "No text available":
        {"English": "No text available", "EspaÃ±ol": "No hay texto disponible"},
    "Treemap":
        {"English": "Treemap", "EspaÃ±ol": "Treemap"},
    "No text available for {column}":
        {"English": "No text available for {column}", "EspaÃ±ol": "No hay texto disponible para {column}"},
    "Color Descriptions":
        {"English": "Color Descriptions", "EspaÃ±ol": "DescripciÃ³n de los Colores"},
    "Network Analysis": {"English": "Network Analysis", "EspaÃ±ol": "AnÃ¡lisis de Red"},
    "Insufficient reviews to perform network analysis.":
        {"English": "Insufficient reviews to perform network analysis.", "EspaÃ±ol": "No hay suficientes reseÃ±as para realizar el anÃ¡lisis de red."},
    "Setting the Word Filter Criteria":
        {"English": "Setting the Word Filter Criteria", "EspaÃ±ol": "Configurar el filtro de palabras"},
    "Minimum word frequency":
        {"English": "Minimum word frequency", "EspaÃ±ol": "Frecuencia mÃ­nima de palabra"},
    "No matching network found with current filter criteria.":
        {"English": "No matching network found with current filter criteria.", "EspaÃ±ol": "No se encontrÃ³ una red con los criterios de filtro actuales."},
    "Color Criteria":
        {"English": "Color Criteria", "EspaÃ±ol": "Criterios de color"},
    "High Frequency words 30%":
        {"English": "High Frequency words 30%", "EspaÃ±ol": "Palabras de alta frecuencia 30%"},
    "Low Frequency words 30%":
        {"English": "Low Frequency words 30%", "EspaÃ±ol": "Palabras de baja frecuencia 30%"},
    "Medium Frequency words":
        {"English": "Medium Frequency words", "EspaÃ±ol": "Palabras de frecuencia media"},
    "Topic Modeling": {"English": "Topic Modeling", "EspaÃ±ol": "Modelado de Temas"},
    "Not enough reviews to run topic modeling.":
        {"English": "Not enough reviews to run topic modeling.", "EspaÃ±ol": "No hay suficientes reseÃ±as para ejecutar el modelado de temas."},
    "Execute Topic Modeling":
        {"English": "Execute Topic Modeling", "EspaÃ±ol": "Ejecutar Modelado de Temas"},
    "Download LDA Result HTML":
        {"English": "ğŸ“ Download LDA Result HTML", "EspaÃ±ol": "ğŸ“ Descargar HTML de resultados LDA"},
    "Customer Satisfaction Analysis":
        {"English": "Customer Satisfaction Analysis", "EspaÃ±ol": "AnÃ¡lisis de SatisfacciÃ³n del Cliente"},
    "Insufficient reviews to perform sentiment analysis.":
        {"English": "Insufficient reviews to perform sentiment analysis.", "EspaÃ±ol": "No hay suficientes reseÃ±as para realizar el anÃ¡lisis de sentimiento."},
    "ğŸ§  Start Customer Satisfaction Analysis":
        {"English": "ğŸ§  Start Customer Satisfaction Analysis", "EspaÃ±ol": "ğŸ§  Iniciar anÃ¡lisis de satisfacciÃ³n del cliente"},
    "Click the button above to start the analysis.":
        {"English": "Click the button above to start the analysis.", "EspaÃ±ol": "Haz clic en el botÃ³n de arriba para iniciar el anÃ¡lisis."},
    "ğŸ” Overall Sentiment Score Comparison":
        {"English": "ğŸ” Overall Sentiment Score Comparison", "EspaÃ±ol": "ğŸ” ComparaciÃ³n General de Sentimiento"},
    "Current Store":
        {"English": "Current Store", "EspaÃ±ol": "Negocio Actual"},
    "Average":
        {"English": "Average", "EspaÃ±ol": "Promedio"},
    "points difference":
        {"English": "points difference", "EspaÃ±ol": "puntos de diferencia"},
    "Keyword Sentiment Score Comparison":
        {"English": "Keyword Sentiment Score Comparison", "EspaÃ±ol": "ComparaciÃ³n de Sentimiento por Palabra Clave"},
    "Insufficient reviews for analysis":
        {"English": "Insufficient reviews for analysis", "EspaÃ±ol": "No hay suficientes reseÃ±as para el anÃ¡lisis"},
    "Points":
        {"English": "Points", "EspaÃ±ol": "Puntos"},
    "Regional Average":
        {"English": "Regional Average", "EspaÃ±ol": "Promedio Regional"},
        "Select Region and Store":
        {"English": "Select Region and Store", "EspaÃ±ol": "Selecciona RegiÃ³n y Negocio"},
    "Please select a region":
        {"English": "Please select a region", "EspaÃ±ol": "Selecciona una regiÃ³n"},
    "Please select a store":
        {"English": "Please select a store", "EspaÃ±ol": "Selecciona un negocio"},
    "âœ…Region/Store Selected":
        {"English": "âœ…Region/Store Selected", "EspaÃ±ol": "âœ…RegiÃ³n/Negocio Seleccionado"},
    "Region":
        {"English": "Region", "EspaÃ±ol": "RegiÃ³n"},
    "Store":
        {"English": "Store", "EspaÃ±ol": "Negocio"},
    "This DCX analysis tool is only permitted for use in the following cases:":
        {"English": "This DCX analysis tool is only permitted for use in the following cases:",
         "EspaÃ±ol": "Esta herramienta de anÃ¡lisis DCX solo se permite usar en los siguientes casos:"},
    "* When used in educational settings such as universities for student education and research":
        {"English": "* When used in educational settings such as universities for student education and research",
         "EspaÃ±ol": "* Cuando se utiliza en entornos educativos como universidades para la educaciÃ³n e investigaciÃ³n estudiantil"},
    "* When used by small business owners for their own business purposes":
        {"English": "* When used by small business owners for their own business purposes",
         "EspaÃ±ol": "* Cuando la utilizan pequeÃ±os empresarios para sus propios fines comerciales"},
    "* When used by university or graduate students as part of nonprofit community service activities to provide business strategies to local small business owners":
        {"English": "* When used by university or graduate students as part of nonprofit community service activities to provide business strategies to local small business owners",
         "EspaÃ±ol": "* Cuando estudiantes universitarios o de posgrado la usan como parte de actividades de servicio comunitario sin fines de lucro para proveer estrategias a pequeÃ±os negocios locales"},
    "Except for the cases above, any commercial use of this analysis tool and reuse of the analysis data is strictly prohibited.":
        {"English": "Except for the cases above, any commercial use of this analysis tool and reuse of the analysis data is strictly prohibited.",
         "EspaÃ±ol": "Excepto en los casos anteriores, cualquier uso comercial de esta herramienta y reutilizaciÃ³n de los datos estÃ¡ estrictamente prohibido."},
    "Inquiries & Information":
        {"English": "Inquiries & Information", "EspaÃ±ol": "Consultas & InformaciÃ³n"},
    "Contact via Email":
        {"English": "Contact via Email", "EspaÃ±ol": "Contacto por Email"},
    "IBA LAB Homepage":
        {"English": "IBA LAB Homepage", "EspaÃ±ol": "PÃ¡gina IBA LAB"},
    "Photos & Reviews":
        {"English": "Photos & Reviews", "EspaÃ±ol": "Fotos y ReseÃ±as"},
    "Word Cloud":
        {"English": "Word Cloud", "EspaÃ±ol": "Nube de Palabras"},
    "Network Analysis":
        {"English": "Network Analysis", "EspaÃ±ol": "AnÃ¡lisis de Red"},
    "Topic Modeling":
        {"English": "Topic Modeling", "EspaÃ±ol": "Modelado de Temas"},
    "Points":
        {"English": "Points", "EspaÃ±ol": "Puntos"},
    "Customer Satisfaction Analysis":
        {"English": "Customer Satisfaction Analysis", "EspaÃ±ol": "AnÃ¡lisis de SatisfacciÃ³n del Cliente"},
    "âœ… Please select a feature":
        {"English": "âœ… Please select a feature", "EspaÃ±ol": "âœ… Selecciona una funciÃ³n"},
    "âœ…Region/Store Selection Finalized":
        {"English": "âœ… Region/Store has been selected", "EspaÃ±ol": "âœ… SelecciÃ³n de RegiÃ³n/Negocio Confirmada"},
    "âš ï¸ Please select the region and store first, then press 'Confirm' to activate the functions.":
        {"English": "âš ï¸ Please select the region and store first, then press 'Confirm' to activate the functions.",
         "EspaÃ±ol": "âš ï¸ Selecciona primero la regiÃ³n y el negocio y luego pulsa 'Confirmar' para activar las funciones."},
}

    # Add more keys/phrases below as you translate your UI!
def T(key):
    return TRANSLATIONS.get(key, {}).get(lang, key)

region_avg_scores = {
    'Pusan National University': {
        'total': 89.05,
        'Taste': 90.12,
        'Service': 87.86,
        'Price': 87.02,
        'Location': 81.43,
        'Atmosphere': 88.63,
        'Hygiene': 89.17
    },
    'Kyung Hee University': {
        'total': 88.87,
        'Taste': 91.05,
        'Service': 87.88,
        'Price': 86.01,
        'Location': 78.23,
        'Atmosphere': 85.76,
        'Hygiene': 89.53
    },
    'Jeju Island': {
        'total': 88.53,
        'Taste': 88.92,
        'Service': 88.00,
        'Price': 81.22,
        'Location': 81.47,
        'Atmosphere': 85.09,
        'Hygiene': 89.87
    }
}

# Force Light Mode
st.markdown("""
<style>
body, .stApp { background-color: white !important; color: black !important; }
[data-testid="stHeader"], [data-testid="stToolbar"], .css-1d391kg, .css-1v0mbdj {
    background-color: white !important;
    color: black !important;
}
.markdown-text-container { color: black !important; }
</style>
""", unsafe_allow_html=True)

# Global settings
os.environ["TOKENIZERS_PARALLELISM"] = "false"
os.environ["STREAMLIT_WATCHER_TYPE"] = "none"

FONT_PATH = "./NanumGothic-Regular.ttf"
font_prop = fm.FontProperties(fname=FONT_PATH)
fm.fontManager.addfont(FONT_PATH)
font_name = font_prop.get_name()
mpl.rcParams['font.family'] = font_name
mpl.rcParams['axes.unicode_minus'] = False
plt.rcParams['font.family'] = font_name
plt.rcParams['axes.unicode_minus'] = False

TIMEZONE = pytz.timezone('Asia/Seoul')

# Dataset mapping
KEYWORD_COLUMNS_KO = ['ë§›', 'ì„œë¹„ìŠ¤', 'ê°€ê²©', 'ìœ„ì¹˜', 'ë¶„ìœ„ê¸°', 'ìœ„ìƒ']
KEYWORD_COLUMNS_EN = ['Taste', 'Service', 'Price', 'Location', 'Atmosphere', 'Hygiene']
KEYWORD_ENGLISH_MAP = dict(zip(KEYWORD_COLUMNS_KO, KEYWORD_COLUMNS_EN))
DATASET_MAP = {
    'Pusan National University': 'IBA-DCX_Analytics_2.0_PNU.csv',
    'Kyung Hee University': 'IBA-DCX_Analytics_2.0_KHU.csv',
    'Jeju Island': 'IBA-DCX_Analytics_2.0_Jeju.csv'
}

# Location English Mapping
LOCATION_ENGLISH_MAP = {
    'Pusan National University': 'Pusan National University',
    'Kyung Hee University': 'Kyung Hee University',
    'Jeju Island': 'Jeju Island'
}

###############################################
# Resource management

@st.cache_resource
def get_classifier():
    return pipeline("sentiment-analysis", model="matthewburke/korean_sentiment")

@st.cache_data
def load_dataset(dataset_name: str) -> pd.DataFrame:
    import gdown
    file_ids = {
        'IBA-DCX_Analytics_2.0_PNU.csv': '1jfMMwnXi5zUOGE6F34B-KjQvfH5jjKmu',
        'IBA-DCX_Analytics_2.0_KHU.csv': '1pqbNRLg8SdsmnZgi9JnqkxjDp7VUPlb4',
        'IBA-DCX_Analytics_2.0_Jeju.csv': '1OeB_VE4bWYCLFAI85ozT7DwiL8V1W7yR'
    }
    file_id = file_ids.get(dataset_name)
    output = f".cache_{dataset_name}"
    if not os.path.exists(output):
        gdown.download(f'https://drive.google.com/uc?id={file_id}', output, quiet=True)
    use_cols = ['Name', 'Content', 'Tokens', 'Image_Links'] + KEYWORD_COLUMNS_KO + ['review_sentences', 'Date']
    df = pd.read_csv(output, usecols=use_cols)
    # Rename Korean columns to English
    df = df.rename(columns=KEYWORD_ENGLISH_MAP)
    return df

@st.cache_resource
def train_lda_model(corpus, _dictionary, num_topics=10):
    return LdaModel(corpus, num_topics=num_topics, id2word=_dictionary, passes=5)

@st.cache_resource
def get_lda_vis_data(_model, corpus, _dictionary):
    return gensimvis.prepare(_model, corpus, _dictionary)

###############################################
# Here used to go the limitations of users
###############################################
# Functions

def compute_sentiment(text, classifier):
    if not isinstance(text, str):
        text = str(text)
    result = classifier(text)
    return result[0]['score'] if result[0]['label'] == 'LABEL_1' else 1 - result[0]['score']

def render_title(location, store):
    st.title(f"{location} - {store}")

def clean_memory(keys):
    for key in keys:
        if key in st.session_state:
            del st.session_state[key]
    plt.clf()
    plt.close('all')
    gc.collect()

def clean_tokens(text):
    text = re.sub(r"[^\w\s]", "", text)  # Remove commas, periods, etc.
    return text.split()

# Stopwords definition (unchanged)
stopwords = {
    # Particles / Pronouns / Demonstratives
    'ì´', 'ê·¸', 'ì €', 'ê²ƒ', 'ê±°', 'ê³³', 'ìˆ˜', 'ì¢€', 'ì²˜ëŸ¼', 'ê¹Œì§€', 'ì—ë„', 'ì—ë„ìš”', 'ì´ë‚˜', 'ë¼ë„',

    # Conjunctions / Connectors
    'ê·¸ë¦¬ê³ ', 'ê·¸ë˜ì„œ', 'ê·¸ëŸ¬ë‚˜', 'í•˜ì§€ë§Œ', 'ë˜í•œ', 'ì¦‰', 'ê²°êµ­', 'ë•Œë¬¸ì—', 'ê·¸ë˜ë„',

    # Predicates / Endings / Auxiliary verbs
    'í•©ë‹ˆë‹¤', 'í•´ìš”', 'í–ˆì–´ìš”', 'í•˜ë„¤ìš”', 'í•˜ì‹œë„¤ìš”', 'í•˜ì‹œë˜ë°ìš”', 'ê°™ì•„ìš”', 'ìˆì–´ìš”', 'ì—†ì–´ìš”',
    'ë˜ë„¤ìš”', 'ë˜ì—ˆì–´ìš”', 'ë³´ì—¬ìš”', 'ëŠê»´ì ¸ìš”', 'í•˜ê² ìŠµë‹ˆë‹¤', 'ë˜ê² ìŠµë‹ˆë‹¤', 'ìˆìŠµë‹ˆë‹¤', 'ì—†ìŠµë‹ˆë‹¤',
    'í•©ë‹ˆë‹¤', 'ì´ì—ìš”', 'ì´ë¼', 'í•´ì„œ',

    # Interjections / Review-specific expressions
    'ã…ã…', 'ã…‹ã…‹', 'ã… ã… ', '^^', '^^;;', '~', '~~', '!!!', '??', '!?', '?!', '...', '!!', '~!!', '~^^!!',

    # Emphasis expressions
    'ì•„ì£¼', 'ì •ë§', 'ì§„ì§œ', 'ì—„ì²­', 'ë§¤ìš°', 'ì™„ì „', 'ë„ˆë¬´', 'êµ‰ì¥íˆ', 'ë§ì´', 'ë§ì•„ìš”', 'ì ë‹¹íˆ', 'ë„˜',

    # Others
    'ì •ë„', 'ëŠë‚Œ', 'ê°™ì€', 'ë‹ˆë‹¹', 'ë„¤ìš”', 'ìˆë„¤ìš”', 'ì´ë„¤ìš”', 'ì´ë¼ì„œ',
    'í•´ì„œìš”', 'ë³´ë‹ˆê¹Œ', 'ë´¤ì–´ìš”', 'ë¨¹ì—ˆì–´ìš”', 'ë§ˆì…¨ì–´ìš”', 'ê°”ì–´ìš”', 'ë´¤ìŠµë‹ˆë‹¤', 'í•˜ëŠ”', 'í•˜ê²Œ', 'ë“œë„¤', 'ë˜ì‹œ',
    'ì´ë‘', 'í•˜ê³ ', 'í•´ë„', 'í•´ë„ìš”', 'ë•Œë¬¸ì—ìš”', 'ì´ë‚˜ìš”', 'ì •ë„ì—ìš”'
}

###############################################
# Modules

# Usage
def render_usage_tab():
    st.header(T("ğŸ“Š IBA-DCX Tool"))

    if lang == "EspaÃ±ol":
        st.markdown("""
        <div style="background-color: #f5f8fa; padding: 20px; border-radius: 12px; border-left: 6px solid #0d6efd;">
            <p style="font-size:16px;">
            <strong>IBA DCX Tool</strong> es una herramienta que apoya el establecimiento de estrategias de gestiÃ³n basadas en la experiencia del cliente a travÃ©s del anÃ¡lisis de reseÃ±as online.<br>
            Puedes realizar las siguientes funciones con esta herramienta.
            </p>
            <ul style="padding-left: 20px; font-size:15px; line-height: 1.6;">
                <li>GeneraciÃ³n de Nube de Palabras</li>
                <li>CreaciÃ³n de GrÃ¡ficos Treemap</li>
                <li>AnÃ¡lisis de Red por Frecuencia</li>
                <li>Modelado de Temas LDA</li>
                <li>AnÃ¡lisis de SatisfacciÃ³n del Cliente vÃ­a AnÃ¡lisis de Sentimiento</li>
            </ul>
        </div>
        <br>
        <br>
        """, unsafe_allow_html=True)

        st.markdown("### âœ… CÃ³mo usar")
        st.markdown("""
        <div style="padding: 16px; background-color: #f9f9f9; border-radius: 10px; font-size: 15px; line-height: 1.7;">
            <ol>
                <li>En la <strong>barra lateral</strong>, selecciona una <span style="color:#0d6efd;">ubicaciÃ³n</span> y <span style="color:#0d6efd;">nombre del negocio</span>, luego haz clic en el botÃ³n <strong>â€˜Confirmarâ€™</strong>.</li>
                <li>Elige la funciÃ³n de anÃ¡lisis deseada del <strong>menÃº desplegable</strong>.</li>
                <li>Para comenzar un nuevo anÃ¡lisis, <strong>actualiza la pÃ¡gina</strong> y comienza de nuevo.</li>
                <li><strong>El anÃ¡lisis de sentimiento</strong> puede demorar mÃ¡s dependiendo del nÃºmero de reseÃ±as.</li>
                <li>Esta herramienta estÃ¡ diseÃ±ada para <strong>modo claro</strong>. Puedes cambiar el tema desde el menÃº (â‹®) en la esquina superior derecha.</li>
            </ol>
            <p style="font-size:14px; color:gray;">
            âš ï¸ Si tienes problemas, contacta al correo en la barra lateral.
            </p>
        </div>
        """, unsafe_allow_html=True)
    else:
        st.markdown("""
        <div style="background-color: #f5f8fa; padding: 20px; border-radius: 12px; border-left: 6px solid #0d6efd;">
            <p style="font-size:16px;">
            <strong>IBA DCX Tool</strong> is a tool that supports <strong>customer experience-based management strategy establishment</strong> through <strong>online review analysis</strong>.<br>
            You can perform the following functions with this tool.
            </p>
            <ul style="padding-left: 20px; font-size:15px; line-height: 1.6;">
                <li>Word Cloud Generation</li>
                <li>Treemap Chart Creation</li>
                <li>Frequency-Based Network Analysis</li>
                <li>LDA Topic Modeling</li>
                <li>Customer Satisfaction Analysis via Sentiment Analysis</li>
            </ul>
        </div>
        <br>
        <br>
        """, unsafe_allow_html=True)

        st.markdown("### âœ… How to Use")

        st.markdown("""
        <div style="padding: 16px; background-color: #f9f9f9; border-radius: 10px; font-size: 15px; line-height: 1.7;">
            <ol>
                <li>In the <strong>sidebar</strong>, select a <span style="color:#0d6efd;">location</span> and <span style="color:#0d6efd;">store name</span>, then click the <strong>â€˜Confirmâ€™</strong> button.</li>
                <li>Choose the desired analysis function from the <strong>function selection dropdown</strong>.</li>
                <li>To start a new analysis, <strong>refresh the page</strong> and begin again.</li>
                <li><strong>Sentiment analysis</strong> may take longer depending on the number of reviews.</li>
                <li>This tool is designed for <strong>Light Mode</strong>. You can change the theme via the menu (â‹®) in the top-right corner.</li>
            </ol>
            <p style="font-size:14px; color:gray;">
            âš ï¸ If you encounter issues, please contact the email address provided in the sidebar.
            </p>
        </div>
        """, unsafe_allow_html=True)

# Review loading
def render_review_tab(df, store):
    st.header(f"{st.session_state.get('selected_location', '')} - {store}: {T('Review Summary and Images')}")
    df_store = df[df['Name'] == store]
    df_store['Tokens'] = df_store['Tokens'].fillna('').map(str).map(clean_tokens)
    image_links = df_store['Image_Links'].tolist()
    reviews = df_store['Content'].fillna('').astype(str).tolist()
    image_pattern = r'https?://[\S]+\.(?:jpg|jpeg|png|gif)'
    all_links, all_reviews = [], []
    for idx, link_str in enumerate(image_links):
        if isinstance(link_str, str):
            links = re.findall(image_pattern, link_str)
            all_links.extend(links)
            all_reviews.extend([reviews[idx]] * len(links))

    # DEMO: Translate displayed reviews if not Korean UI
    # (You can choose 'en' for English, 'es' for Spanish)
    googletrans_langs = {"English": "en", "EspaÃ±ol": "es"}
    display_reviews = all_reviews
    if lang in googletrans_langs and lang != "í•œêµ­ì–´":  # if not Korean UI
        display_reviews = translate_texts(all_reviews, googletrans_langs[lang])

    avg_length = np.mean([len(r) for r in reviews if isinstance(r, str)]) if reviews else 0
    st.markdown(f"### ğŸ“Š {T('Review Indicators')}")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric(T("Total number of Reviews"), f"{len(df_store)} reviews")
    with col2:
        st.metric(T("Total number of Images"), f"{len(all_links)} images")
    with col3:
        st.metric(T("Average Review Length"), f"{avg_length:.1f}")

    st.markdown(f"### {T('Top Reviews ğŸ–¼ï¸')}")
    NUM_CARDS = 6
    if 'review_indices' not in st.session_state:
        st.session_state.review_indices = random.sample(range(len(all_links)), min(NUM_CARDS, len(all_links)))
    if st.button(T("ğŸ”„ Look at other reviews")):
        st.session_state.review_indices = random.sample(range(len(all_links)), min(NUM_CARDS, len(all_links)))
    for row_start in range(0, len(st.session_state.review_indices), 3):
        row_cols = st.columns(3)
        for i in range(3):
            if row_start + i >= len(st.session_state.review_indices):
                break
            idx = st.session_state.review_indices[row_start + i]
            with row_cols[i]:
                st.markdown(f"""
                <div style="height: 180px; overflow: hidden; border-radius: 8px;">
                    <img src="{all_links[idx]}" style="width: 100%; height: 100%; object-fit: cover; border-radius: 8px;" />
                </div>
                """, unsafe_allow_html=True)

                # Show the translated review
                highlighted = display_reviews[idx]
                st.markdown(f"""
                <div style="padding:12px; background-color:#f9f9f9; border-radius:10px;
                            box-shadow:0 2px 4px rgba(0,0,0,0.08); margin-top:8px;
                            height:150px; overflow:auto;">
                    <p style="font-size:14px; color:#333;">{highlighted}</p>
                </div>
                """, unsafe_allow_html=True)

# Wordcloud
# Define vivid color list
VIVID_COLORS = ["#1f77b4", "#ff7f0e", "#2ca02c", "#d62728", "#9467bd", "#e31a1c", "#17becf"]

# Random color function
def vivid_color_func(*args, **kwargs):
    return choice(VIVID_COLORS)

# Wordcloud tab rendering function
def render_wordcloud_tab(df, store):
    st.header(f"{st.session_state.get('selected_location', '')} - {store}: {T('Wordcloud')}")
    df_store = df[df['Name'] == store]
    df_store['Tokens'] = df_store['Tokens'].fillna('').map(str).map(clean_tokens)

    columns_to_plot = ['Content'] + KEYWORD_COLUMNS_EN

    container = st.container()
    cols = container.columns(3)

    for idx, column in enumerate(columns_to_plot):
        col = cols[idx % 3]
        text = ' '.join(df_store[column].dropna().map(str))
        tokens = text.split()
        filtered_tokens = [t for t in tokens if t not in stopwords]
        filtered_text = ' '.join(filtered_tokens)

        with col:
            st.markdown(
                f"<div style='text-align:center; font-weight:bold; font-size:16px; margin-bottom:5px;'>{column}</div>",
                unsafe_allow_html=True
            )

            if filtered_text.strip():
                wordcloud = WordCloud(
                    font_path=FONT_PATH,
                    width=800,
                    height=800,
                    contour_width=1.8,
                    contour_color='black',
                    background_color='white',
                    mode='RGB',
                    color_func=vivid_color_func,
                    collocations=False
                ).generate(filtered_text)

                fig, ax = plt.subplots(figsize=(5, 5), dpi=150)
                ax.imshow(wordcloud, interpolation='nearest')
                ax.axis('off')
                st.pyplot(fig)
                plt.close(fig)
            else:
                st.markdown(f"""
                <div style="padding:10px; text-align:center; background-color:#f9f9f9;
                            border-radius:10px; min-height:200px; height:260px;
                            display:flex; align-items:center; justify-content:center;">
                    <span style="color:gray;">{T('No text available')}</span>
                </div>
                """, unsafe_allow_html=True)

# Treemap
def render_treemap_tab(df, store):
    st.header(f"{st.session_state.get('selected_location', '')} - {store}: {T('Treemap')}")
    df_store = df[df['Name'] == store]
    df_store['Tokens'] = df_store['Tokens'].fillna('').map(str).map(clean_tokens)

    columns_to_plot = ['Content'] + KEYWORD_COLUMNS_EN
    container = st.container()
    cols = container.columns(3)

    for idx, column in enumerate(columns_to_plot):
        col = cols[idx % 3]
        text = ' '.join(df_store[column].dropna().map(str))

        tokens = text.split()
        filtered_tokens = [t for t in tokens if t not in stopwords]
        word_count = Counter(filtered_tokens)

        with col:
            st.markdown(f"<div style='text-align:center; font-weight:bold; font-size:16px; margin-bottom:5px;'>{column}</div>", unsafe_allow_html=True)

            if filtered_tokens and len(word_count) > 0:
                most_common = word_count.most_common(10)
                sizes = [count for _, count in most_common]
                labels = [f"{word} ({count})" for word, count in most_common]

                cmap = plt.cm.get_cmap("Blues")
                normed_sizes = [s / max(sizes) for s in sizes]
                colors = [cmap(0.3 + 0.7 * s) for s in normed_sizes]

                fig, ax = plt.subplots(figsize=(4, 4))
                squarify.plot(sizes=sizes, label=labels, color=colors, alpha=0.85, ax=ax, text_kwargs={'fontsize':10})
                ax.axis('off')
                st.pyplot(fig)
                plt.close(fig)
            else:
                st.markdown(f"""
                <div style="padding:20px; text-align:center; background-color:#f9f9f9;
                            border-radius:10px; min-height:260px;
                            display:flex; align-items:center; justify-content:center;
                            box-shadow:0px 1px 3px rgba(0,0,0,0.05);">
                    <span style="color:gray; font-size:16px;">{T('No text available for {column}').format(column=column)}</span>
                </div>
                """, unsafe_allow_html=True)

    with st.expander(f"ğŸ“˜ {T('Color Descriptions')}"):
        if lang == "EspaÃ±ol":
            st.markdown("""
            - El **color del treemap representa la frecuencia relativa** de la palabra.
            - **Azul oscuro** indica una palabra mencionada mÃ¡s frecuentemente.
            - **Colores claros** representan palabras con menor frecuencia.
            """)
        else:
            st.markdown("""
            - The **color of the treemap represents the relative frequency** of the word.  
            - **Dark blue** indicates a more frequently mentioned word.  
            - **Light colors** represent words with lower frequency.
            """)

# Network analysis
def render_network_tab(df, store):
    st.header(f"{st.session_state.get('selected_location', '')} - {store}: {T('Network Analysis')}")
    df_store = df[df['Name'] == store]

    if len(df_store) < 20:
        st.warning(T("Insufficient reviews to perform network analysis."))
        return

    def clean_tokens(text):
        text = re.sub(r"[^\w\s]", "", text)
        return text.split()
    
    df_store['Tokens'] = df_store['Tokens'].fillna('').map(str).map(clean_tokens)

    st.subheader(T("Setting the Word Filter Criteria"))
    total_reviews = len(df_store)
    min_value = max(1, total_reviews // 20)
    max_value = max(2, total_reviews // 10)
    default_value = (min_value + max_value) // 2

    min_freq = st.slider(
        T("Minimum word frequency"),
        min_value=min_value,
        max_value=max_value,
        value=default_value
    )

    word_freq = Counter(itertools.chain(*df_store['Tokens']))
    filtered_words = {w for w, c in word_freq.items() if c >= min_freq}

    df_store['Filtered_Tokens'] = df_store['Tokens'].apply(
        lambda tokens: [w for w in tokens if w in filtered_words and w not in stopwords and len(w) > 1]
    )

    co_occurrence = defaultdict(int)
    for tokens in df_store['Filtered_Tokens']:
        for pair in itertools.combinations(set(tokens), 2):
            co_occurrence[tuple(sorted(pair))] += 1

    G = nx.Graph()
    for (w1, w2), freq in co_occurrence.items():
        G.add_edge(w1, w2, weight=freq)

    G.remove_nodes_from(list(nx.isolates(G)))

    if G.number_of_nodes() == 0:
        st.warning(T("No matching network found with current filter criteria."))
        return

    pos = nx.spring_layout(G, k=0.5, seed=42)
    degree_centrality = nx.degree_centrality(G)

    freq_dict = {node: word_freq.get(node, 0) for node in G.nodes()}
    freq_values = list(freq_dict.values())
    upper_thresh = np.percentile(freq_values, 70)
    lower_thresh = np.percentile(freq_values, 30)

    def get_color(freq):
        if freq >= upper_thresh:
            return 'green'
        elif freq <= lower_thresh:
            return 'crimson'
        else:
            return 'skyblue'

    node_colors = [get_color(freq_dict[n]) for n in G.nodes()]

    fig, ax = plt.subplots(figsize=(8, 7))
    fig.subplots_adjust(top=0.88, bottom=0.15)
    node_sizes = [1000 + len(n) * 250 for n in G.nodes()]
    
    nx.draw_networkx_nodes(G, pos, node_color=node_colors, node_size=node_sizes, ax=ax)
    nx.draw_networkx_edges(G, pos, edge_color='lightgray', ax=ax, alpha=0.5)
    nx.draw_networkx_labels(G, pos, font_size=12, font_family=font_prop.get_name(), ax=ax)
    
    ax.set_title(f"{store} - {T('Network Analysis')}", fontproperties=font_prop, fontsize=16, pad=12)
    ax.axis('off')
    st.pyplot(fig)
    plt.close(fig)

    with st.expander(f"ğŸŒˆ {T('Color Criteria')}"):
        if lang == "EspaÃ±ol":
            st.markdown(f"""
            - ğŸŸ¢ **Verde**: {T("High Frequency words 30%")}
            - ğŸ”´ **Rojo**: {T("Low Frequency words 30%")}
            - ğŸ”µ **Azul**: {T("Medium Frequency words")}
            """)
        else:
            st.markdown(f"""
            - ğŸŸ¢ **Green**: {T("High Frequency words 30%")}  
            - ğŸ”´ **Red**: {T("Low Frequency words 30%")}  
            - ğŸ”µ **Blue**: {T("Medium Frequency words")}
            """)

# Topic modeling
def render_topic_tab(df, store):
    st.header(f"{st.session_state.get('selected_location', '')} - {store}: {T('Topic Modeling')}")
    df_store = df[df['Name'] == store]
    df_store['Tokens'] = df_store['Tokens'].fillna('').map(str).map(clean_tokens)
    if len(df_store) < 50:
        st.warning(T("Not enough reviews to run topic modeling."))
        return

    df_store['Tokens'] = df_store['Tokens'].fillna('').map(str).map(str.split)
    if len(df_store) > 300:
        df_store = df_store.sample(300, random_state=42)

    dictionary = corpora.Dictionary(df_store['Tokens'])
    corpus = [dictionary.doc2bow(text) for text in df_store['Tokens']]

    if st.button(T("Execute Topic Modeling")):
        lda_model = train_lda_model(corpus, dictionary)
        vis_data = get_lda_vis_data(lda_model, corpus, dictionary)
        with tempfile.NamedTemporaryFile("w+", delete=False, suffix=".html") as f:
            pyLDAvis.save_html(vis_data, f.name)
            html_path = f.name
        with open(html_path, "r", encoding="utf-8") as f:
            html_content = f.read()
        b64 = base64.b64encode(html_content.encode()).decode()
        st.markdown(f'<a href="data:text/html;base64,{b64}" download="lda_result.html">{T("Download LDA Result HTML")}</a>', unsafe_allow_html=True)
        del lda_model, vis_data, corpus, dictionary
        gc.collect()

# Sentiment analysis
def render_sentiment_dashboard(df, store, classifier):
    region_avg_scores = {
        'Pusan National University': {
            'total': 89.05,
            'Taste': 90.12,
            'Service': 87.86,
            'Price': 87.02,
            'Location': 81.43,
            'Atmosphere': 88.63,
            'Hygiene': 89.17
        },
        'Kyung Hee University': {
            'total': 88.87,
            'Taste': 91.05,
            'Service': 87.88,
            'Price': 86.01,
            'Location': 78.23,
            'Atmosphere': 85.76,
            'Hygiene': 89.53
        },
        'Jeju Island': {
            'total': 88.53,
            'Taste': 88.92,
            'Service': 88.00,
            'Price': 81.22,
            'Location': 81.47,
            'Atmosphere': 85.09,
            'Hygiene': 89.87
        }
    }
    st.header(f"{LOCATION_ENGLISH_MAP.get(st.session_state.get('selected_location', ''))} - {store}: {T('Customer Satisfaction Analysis')}")
    df_store = df[df['Name'] == store]

    if len(df_store) < 50:
        st.warning(T("Insufficient reviews to perform sentiment analysis."))
        return

    sentiment_key = f"sentiment_scores_{store}"

    if sentiment_key not in st.session_state:
        if st.button(T("ğŸ§  Start Customer Satisfaction Analysis")):
            texts = df_store['review_sentences'].dropna().astype(str).tolist()
            keyword_inputs = {col: df_store[col].dropna().astype(str).tolist() for col in KEYWORD_COLUMNS_EN}
            total_steps = len(texts) + sum(len(v) for v in keyword_inputs.values())
            completed_steps = 0
            progress_bar = st.progress(0)

            total_scores = []
            for text in texts:
                result = classifier(text)[0]
                score = result['score'] if result['label'] == 'LABEL_1' else 1 - result['score']
                total_scores.append(score)
                completed_steps += 1
                progress_bar.progress(completed_steps / total_steps)

            keyword_scores = {}
            for col, col_texts in keyword_inputs.items():
                if col_texts:
                    scores = []
                    for text in col_texts:
                        result = classifier(text)[0]
                        score = result['score'] if result['label'] == 'LABEL_1' else 1 - result['score']
                        scores.append(score)
                        completed_steps += 1
                        progress_bar.progress(completed_steps / total_steps)
                    keyword_scores[col] = np.mean(scores) * 100
                else:
                    keyword_scores[col] = None

            st.session_state[sentiment_key] = {
                'total': np.mean(total_scores) * 100,
                'keywords': keyword_scores
            }
        else:
            st.info(T("Click the button above to start the analysis."))
            return

    # Visualize results
    region_name = st.session_state.get('selected_location', '')
    region_stats = region_avg_scores.get(region_name, {})
    sentiment_data = st.session_state[sentiment_key]

    # Overall score comparison
    st.subheader(T("ğŸ” Overall Sentiment Score Comparison"))

    store_total = sentiment_data['total']
    region_total = region_stats.get('total', None)

    if region_total is not None:
        diff = store_total - region_total
        trend_icon = "â–²" if diff > 0 else ("â–¼" if diff < 0 else "â–¶")
        trend_color = "green" if diff > 0 else ("crimson" if diff < 0 else "gray")
        trend_text = f"{trend_icon} {abs(diff):.2f} {T('points difference')}"
    else:
        trend_text = "-"
        trend_color = "gray"

    col1, col2 = st.columns(2)

    box_style_total = """
        padding: 20px;
        border-radius: 15px;
        background-color: #f5f5f5;
        text-align: center;
        box-shadow: 0px 1px 4px rgba(0,0,0,0.1);
        min-height: 170px;
        display: flex;
        flex-direction: column;
        justify-content: center;
"""

    with col1:
        st.markdown(f"""
        <div style="{box_style_total}">
            <div style="font-size:18px; font-weight:bold;">{T("Current Store")}</div>
            <div style="font-size:36px; font-weight:bold; color:#2b8a3e;">{store_total:.2f} Points</div>
        </div>
        """, unsafe_allow_html=True)

    with col2:
        st.markdown(f"""
        <div style="{box_style_total}">
            <div style="font-size:18px; font-weight:bold;">{region_name} {T("Average")}</div>
            <div style="font-size:36px; font-weight:bold; color:#1c7ed6;">{region_total:.2f} Points</div>
            <div style="font-size:16px; color:{trend_color}; margin-top:5px;">{trend_text}</div>
        </div>
        """, unsafe_allow_html=True)

    st.subheader(f"ğŸ” {T('Keyword Sentiment Score Comparison')}")
    keyword_data = sentiment_data["keywords"]
    cols = st.columns(3)

    for idx, keyword in enumerate(KEYWORD_COLUMNS_EN):
        with cols[idx % 3]:
            store_score = keyword_data.get(keyword)
            region_score = region_stats.get(keyword)

            box_style = """
                padding: 15px;
                border-radius: 10px;
                background-color: whitesmoke;
                text-align: center;
                box-shadow: 0px 1px 3px rgba(0,0,0,0.05);
                min-height: 130px;
                display: flex;
                flex-direction: column;
                justify-content: center;
            """

            if store_score is None:
                st.markdown(f"""
                    <div style="{box_style}">
                        <div style="font-size:18px; font-weight:bold">{keyword}</div>
                        <div style="font-size:16px; color:gray; margin-top:12px;">{T('Insufficient reviews for analysis')}</div>
                    </div>
                """, unsafe_allow_html=True)
            else:
                diff = store_score - region_score if region_score else 0
                trend = "â–²" if diff > 0 else ("â–¼" if diff < 0 else "-")
                color = "green" if diff > 0 else ("crimson" if diff < 0 else "gray")

                st.markdown(f"""
                    <div style="{box_style}">
                        <div style="font-size:18px; font-weight:bold">{keyword}</div>
                        <div style="font-size:28px; color:{color}">{store_score:.2f}{T(' Points')} {trend}</div>
                        <div style="font-size:14px; color:gray">{T('Regional Average')}: {region_score:.2f}{T(' Points')}</div>
                    </div>
                """, unsafe_allow_html=True)
       
###############################################
# UI

# Sidebar
st.sidebar.image("DCX_Tool.png", use_container_width=True)
st.sidebar.title(T("Select Region and Store"))

if 'location_locked' not in st.session_state:
    st.session_state['location_locked'] = False

if not st.session_state['location_locked']:
    location = st.sidebar.selectbox(T("Please select a region"), [''] + list(DATASET_MAP.keys()), key="loc")
    if location:
        df = load_dataset(DATASET_MAP[location])
        stores = df['Name'].value_counts().index.tolist()
        store = st.sidebar.selectbox(T("Please select a store"), [''] + stores, key="store")
        if store and st.sidebar.button(T("âœ…Region/Store Selection Finalized")):
            st.session_state.update({
                'location_locked': True,
                'selected_location': location,
                'selected_store': store
            })
else:
    location = st.session_state.get('selected_location')
    store = st.session_state.get('selected_store')
    st.sidebar.markdown(f"ğŸ”’ {T('Region')}: {location}\n\nğŸ”’ {T('Store')}: {store}")
    df = load_dataset(DATASET_MAP[location])

# Usage rules (bilingual markdown)
if lang == "EspaÃ±ol":
    st.sidebar.markdown(f"""
    ## **{T('This DCX analysis tool is only permitted for use in the following cases:')}**
    {T('* When used in educational settings such as universities for student education and research')}
    {T('* When used by small business owners for their own business purposes')}
    {T('* When used by university or graduate students as part of nonprofit community service activities to provide business strategies to local small business owners')}
    <span style="color:red; font-weight:bold">
    {T('Except for the cases above, any commercial use of this analysis tool and reuse of the analysis data is strictly prohibited.')}
    </span>
    <br><br><br>
    """, unsafe_allow_html=True)
else:
    st.sidebar.markdown(f"""
    ## **{T('This DCX analysis tool is only permitted for use in the following cases:')}**
    {T('* When used in educational settings such as universities for student education and research')}
    {T('* When used by small business owners for their own business purposes')}
    {T('* When used by university or graduate students as part of nonprofit community service activities to provide business strategies to local small business owners')}
    <span style="color:red; font-weight:bold">
    {T('Except for the cases above, any commercial use of this analysis tool and reuse of the analysis data is strictly prohibited.')}
    </span>
    <br><br><br>
    """, unsafe_allow_html=True)

st.sidebar.markdown(f"""
<div style="text-align:center; font-size:16px; font-weight:bold; margin-bottom:10px;">
ğŸ“¬ {T("Inquiries & Information")}
</div>

<a href="mailto:peter@pusan.ac.kr">
    <button style="
        background-color:#f59f00;
        color:white;
        padding:8px 14px;
        border:none;
        border-radius:5px;
        font-size:14px;
        width:100%;
        margin-bottom:8px;
        cursor:pointer;">
        ğŸ“§ {T("Contact via Email")}
    </button>
</a>

<a href="https://ibalab.quv.kr/" target="_blank">
    <button style="
        background-color:#1c7ed6;
        color:white;
        padding:8px 14px;
        border:none;
        border-radius:5px;
        font-size:14px;
        width:100%;
        cursor:pointer;">
        ğŸŒ {T("IBA LAB Homepage")}
    </button>
</a>
""", unsafe_allow_html=True)

# Tab setup (all bilingual)
TABS = [
    T("How to Use"),
    T("Photos & Reviews"),
    T("WordCloud"),
    T("Treemap"),
    T("Network Analysis"),
    T("Topic Modeling"),
    T("Customer Satisfaction Analysis")
]

if 'current_tab' not in st.session_state:
    st.session_state['current_tab'] = T("How to Use")

# Force color for selectbox label and warning text
st.markdown("""
<style>
label[for^=""] {
    color: black !important;
    font-weight: 600;
}
div[data-testid="stMarkdownContainer"] p {
    color: black !important;
}
</style>
""", unsafe_allow_html=True)

if st.session_state.get("location_locked", False):
    selected_tab = st.selectbox(T("âœ… Please select a feature"), TABS)
    if st.session_state['current_tab'] != selected_tab:
        keys_to_clear = [
            key for key in st.session_state.keys()
            if key not in (
                'selected_location', 
                'selected_store', 
                'location_locked', 
                'user_id', 
                'queue_checked', 
                'start_time'
            )
        ]

        for k in keys_to_clear:
            del st.session_state[k]
        plt.clf()
        plt.close('all')
        gc.collect()
        st.session_state['current_tab'] = selected_tab
else:
    selected_tab = T("How to Use")
    st.warning(T("âš ï¸ Please select the region and store first, then press 'Confirm' to activate the functions."))

# Execute tab-specific functions (mapping bilingual tab names to functions)
tab_map = {
    T("How to Use"): render_usage_tab,
    T("Photos & Reviews"): render_review_tab,
    T("Word Cloud"): render_wordcloud_tab,
    T("Treemap"): render_treemap_tab,
    T("Network Analysis"): render_network_tab,
    T("Topic Modeling"): render_topic_tab,
    T("Customer Satisfaction Analysis"): lambda: render_sentiment_dashboard(df, store, get_classifier()),
}

if selected_tab in tab_map:
    # Photos & Reviews, Word Cloud, Treemap, Network Analysis, Topic Modeling take df, store
    if selected_tab in [T("Photos & Reviews"), T("Word Cloud"), T("Treemap"), T("Network Analysis"), T("Topic Modeling")]:
        tab_map[selected_tab](df, store)
    elif selected_tab == T("How to Use"):
        tab_map[selected_tab]()
    else:  # Sentiment
        tab_map[selected_tab]()

